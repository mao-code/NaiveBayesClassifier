{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mao-code/NaiveBayesClassifier/blob/main/%5BNLP_2023%5D_Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "x6ZHOucvOOza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download(\"movie_reviews\") # corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8D8UDUCZlc",
        "outputId": "160d8dff-ac46-438e-9007-2f29dfb18890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training data"
      ],
      "metadata": {
        "id": "ASdzF0cgrFRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import math \n",
        "import random\n",
        "\n",
        "train_X, train_Y = [], []\n",
        "test_X, test_Y = [], []\n",
        "\n",
        "random.seed(0)\n",
        "for polarity in movie_reviews.categories(): # 看正評負評\n",
        "    for fid in movie_reviews.fileids(polarity):\n",
        "        if random.randrange(5) == 0:\n",
        "            test_X.append([w for w in movie_reviews.words(fid)])\n",
        "            test_Y.append(polarity)\n",
        "        else:\n",
        "            train_X.append([w for w in movie_reviews.words(fid)])\n",
        "            train_Y.append(polarity)\n",
        "\n",
        "print(train_X[0], train_Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyfLD0SRChBr",
        "outputId": "1149caf6-f0e3-4670-bf08-0be5221f36f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'] neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAq_FufBWanu",
        "outputId": "61b2c447-0be2-4c9b-eb58-d2a575223732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Version Model Construction\n",
        "* 這邊的訓練沒有用到loss等等, 只是在做統計\n",
        "* Generative Training"
      ],
      "metadata": {
        "id": "8TiSvHHAhy6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class NaiveBayesClassifier:\n",
        "#     def __init__(self, k=0.5): # k for smoothing\n",
        "#         self.k = k\n",
        "#         self.features = set() # 詞彙表 (不重複)\n",
        "#         self.class_feature_counts = defaultdict(Counter) # 某個詞是正評/負評的次數\n",
        "#         self.class_counts = Counter() # 正評/負評 次數\n",
        "#         self.total = 0 # total reviews\n",
        "\n",
        "#     def train(self, train_X, train_Y):\n",
        "#         for tokens, label in zip(train_X, train_Y): # tokens for a review (tokenized)\n",
        "#             self.class_counts[label] += 1\n",
        "#             self.total += 1\n",
        "#             for token in set(tokens):\n",
        "#                 self.features.add(token)\n",
        "#                 self.class_feature_counts[label][token] += 1\n",
        "    \n",
        "#     def probabilities(self, token): # 回傳每個token對於所有類別(正評或負評)的條件機率\n",
        "#         probs = {}\n",
        "#         for cls, cls_cnt in self.class_counts.items():\n",
        "#             probs[cls] = (self.class_feature_counts[cls][token] + self.k) / (cls_cnt + 2 * self.k)\n",
        "#         return probs\n",
        "\n",
        "#     def predict(self, tokens):\n",
        "#         tokens = set(tokens)\n",
        "#         log_probs = Counter()\n",
        "#         for cls, cls_cnt in self.class_counts.items(): # 類別\n",
        "#             # to avoid underflow (所以轉成log), 連乘也比較容易\n",
        "#             # P(y)\n",
        "#             log_probs[cls] = math.log(cls_cnt / self.total) \n",
        "#         for token in self.features: # 每個類別之於每個token\n",
        "#             probs = self.probabilities(token) \n",
        "#             if token in tokens: # seen\n",
        "#                 for cls, prob in probs.items():\n",
        "#                     # P(y|x_i)/P(x_i)\n",
        "#                     log_probs[cls] += math.log(prob)\n",
        "#             else: # unseen\n",
        "#                 for cls, prob in probs.items():\n",
        "#                     log_probs[cls] += math.log(1.0 - prob) # 如果feature沒有出現在測試tokens內 (不能直接乘機率)\n",
        "#         # Return the argmax of log_probs and all log_probs\n",
        "#         return max(log_probs, key=log_probs.get), log_probs  "
      ],
      "metadata": {
        "id": "fobAkWURDr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified Model\n",
        "\n"
      ],
      "metadata": {
        "id": "iF3-x6R32FUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k=0.3): # k for smoothing, Big for small dataset(avoid overfitting)\n",
        "        self.k = k\n",
        "        self.features = set() \n",
        "        self.class_feature_counts = defaultdict(Counter) \n",
        "        self.class_counts = Counter() \n",
        "        self.total = 0 \n",
        "\n",
        "    def train(self, train_X, train_Y):\n",
        "        for tokens, label in zip(train_X, train_Y): \n",
        "            self.class_counts[label] += 1\n",
        "            self.total += 1\n",
        "            for token in set(tokens):\n",
        "                self.features.add(token)\n",
        "                self.class_feature_counts[label][token] += 1\n",
        "    \n",
        "    def probabilities(self, token): \n",
        "        probs = {}\n",
        "        for cls, cls_cnt in self.class_counts.items():\n",
        "            # C(x_i, y) + k / C(Y) + |Y|*k\n",
        "            probs[cls] = (self.class_feature_counts[cls][token] + self.k) / (cls_cnt + 2 * self.k) # (|Y| = 2)\n",
        "        return probs\n",
        "\n",
        "    def prob_class_given_feature(self, feature, cls):\n",
        "        probs = self.probabilities(feature)\n",
        "        return probs[cls] / sum(probs.values())\n",
        "\n",
        "    def predict(self, tokens):\n",
        "        # 介系詞, 冠詞, 代名詞不要 (跑太久)\n",
        "        # meaningful_features = list(filter(lambda t: nltk.pos_tag([t])[0][1] != 'DT' and nltk.pos_tag([t])[0][1] != 'IN' and nltk.pos_tag([t])[0][1] != 'PRP' ,self.features))\n",
        "\n",
        "        # 去除低頻特徵\n",
        "        high_freq_ft = filter(lambda t: self.class_feature_counts[\"pos\"][t] >= 20 or self.class_feature_counts[\"neg\"][t] >=20, self.features)\n",
        "\n",
        "        # polarity 顯著\n",
        "        # 不要兩者機率都很高的(有可能是沒有鑑別力的特徵)\n",
        "        high_freq_pol_ft = list(filter(lambda t: abs(self.prob_class_given_feature(t, \"pos\") - self.prob_class_given_feature(t, \"neg\")) >= 0.02, high_freq_ft))\n",
        "        \n",
        "        tokens = set(tokens)\n",
        "        log_probs = Counter()\n",
        "        for cls, cls_cnt in self.class_counts.items(): \n",
        "            log_probs[cls] = math.log(cls_cnt / self.total) \n",
        "        for token in high_freq_pol_ft: # 只看重要特徵\n",
        "            probs = self.probabilities(token) \n",
        "            if token in tokens: \n",
        "                for cls, prob in probs.items():\n",
        "                    log_probs[cls] += math.log(prob)\n",
        "            else: \n",
        "                for cls, prob in probs.items():\n",
        "                    log_probs[cls] += math.log(1.0 - prob)\n",
        "        # Return the argmax of log_probs and all log_probs\n",
        "        return max(log_probs, key=log_probs.get), log_probs  "
      ],
      "metadata": {
        "id": "cTgFwZtm2EpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Model"
      ],
      "metadata": {
        "id": "GE_Ht04wh3Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.train(train_X, train_Y)"
      ],
      "metadata": {
        "id": "5rdZQ-aJhtld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.prob_class_given_feature('the', 'pos'), model.prob_class_given_feature('the', 'neg'))\n",
        "print(model.prob_class_given_feature('good', 'pos'), model.prob_class_given_feature('good', 'neg'))\n",
        "print(model.prob_class_given_feature('excellent', 'pos'), model.prob_class_given_feature('excellent', 'neg'))\n",
        "print(model.prob_class_given_feature('bad', 'pos'), model.prob_class_given_feature('good', 'neg'))\n",
        "print(model.prob_class_given_feature('still', 'pos'), model.prob_class_given_feature('good', 'neg'))\n",
        "print(model.prob_class_given_feature('banana', 'pos'), model.prob_class_given_feature('banana', 'neg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfTnoLgaXYlR",
        "outputId": "e61ab706-0c67-4265-dbe5-0f4b74907fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5003319651135077 0.49966803488649225\n",
            "0.5106548113655963 0.4893451886344036\n",
            "0.7291860406263813 0.2708139593736188\n",
            "0.3332788733234873 0.4893451886344036\n",
            "0.5347407236645865 0.4893451886344036\n",
            "0.5379388361319317 0.4620611638680683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Taken from https://www.imdb.com/review/rw0990793/?ref_=tt_urv\n",
        "review = \"\"\"A whimsical, often spectacular view of a future in which advances in technology dominate the world. It is well shot and although slow-moving it is intense and enjoyable throughout. The featuring of classical music to establish atmosphere works brilliantly; it provides a feeling of awe, mystery and intrigue  the same aura that Walt Disney worked in creating 'Fantasia'. The special effects, both sound and visual, are still spellbinding by the standards of today's technology. Aside from the technical pluses of the film, it stands strong as it is one of not many films out there that has something important to say about humankind, and where the human race is heading in terms of our increasing reliance on machines and our unquenchable thirst to discover. Despite an ending that is hard to understand, it is even harder to overlook this film a true cinema classic.\"\"\"\n",
        "\n",
        "model.predict(word_tokenize(review.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeH93xRFZ1EF",
        "outputId": "e07e8bb8-3b10-483d-d1b4-40781ff90b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pos', Counter({'neg': -323.42477515116457, 'pos': -313.96038133888857}))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "\n",
        "for x, y in zip(test_X, test_Y):\n",
        "    prediction, _ = model.predict(x)\n",
        "    if prediction == y:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "# highest score: 0.86019\n",
        "print(\"Acc: %d / %d = %g\" % (correct, total, correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lkFRJ0FKbc",
        "outputId": "18f919f1-f6e2-4933-cd03-9310eb4874be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc: 363 / 422 = 0.86019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring important features"
      ],
      "metadata": {
        "id": "pmqZUqeTgjzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_class_given_feature(feature, cls, model):\n",
        "    probs = model.probabilities(feature)\n",
        "    return probs[cls] / sum(probs.values())\n",
        "\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"pos\", model), reverse=True)[:30])\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"neg\", model), reverse=True)[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xofcbwlXgluq",
        "outputId": "02f568f2-c301-4c36-ff45-6472a1afe734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thematic', 'astounding', 'dread', 'turturro', 'reminder', 'naval', 'kenobi', 'seamless', 'denial', 'en', 'fascination', 'keen', 'masterfully', 'lovingly', 'ideology', 'ideals', 'balancing', 'timeless', 'missteps', 'supports', 'burbank', 'musicals', 'topping', 'springer', 'fabric', 'tide', 'downside', 'online', 'uncut', 'hypocrisy']\n",
            "['hudson', 'illogical', 'sans', 'yell', '3000', 'overwrought', 'degenerates', 'tedium', 'undermines', 'bio', 'pathetically', 'horrid', 'guinea', 'hmmm', 'leaden', 'lectures', 'biologist', 'vomit', 'chevy', 'batgirl', 'setups', 'campiness', 'plodding', 'stupidly', 'zellweger', 'plastered', 'croft', 'consecutive', 'embarassing', 'weaponry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QLtuGLXw-Kcx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}